{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.258277Z",
     "start_time": "2024-06-05T20:01:58.248098Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utility import plot_model_history, execute_grid_search\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "\n",
    "# defining parameters\n",
    "num_words = 3000  #this means we can consider only the top  3,000 most frequent words\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c27a19db449b431b",
   "metadata": {},
   "source": [
    "## Data preparation \n",
    "- import data and examine the data\n",
    "- Remove inconsistencies, irrelevant information\n",
    "- Correct inconsistent formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e3953e92a44d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.301157Z",
     "start_time": "2024-06-05T20:01:58.274441Z"
    }
   },
   "source": [
    "email_datasets = pd.read_csv('test_data.csv')\n",
    "\n",
    "email_datasets.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ec82ed9616b95e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.306479Z",
     "start_time": "2024-06-05T20:01:58.302553Z"
    }
   },
   "source": [
    "print(email_datasets.head())\n",
    "print(email_datasets.isnull().sum())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a285693508ef9fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.310758Z",
     "start_time": "2024-06-05T20:01:58.307187Z"
    }
   },
   "source": [
    "# rename Category to category & Message to message for consistency between labels features\n",
    "\n",
    "email_datasets.columns = ['category', 'message']\n",
    "\n",
    "print(email_datasets.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f3e5bea9070fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.317992Z",
     "start_time": "2024-06-05T20:01:58.311910Z"
    }
   },
   "source": [
    "# converting  all spam to ham and all upper case to lower case in the texts so that preprocessing can occur correctly\n",
    "\n",
    "email_datasets.category = email_datasets.category.apply(lambda x: 1 if x == 'spam' else 0)\n",
    "email_datasets.message = email_datasets.message.apply(lambda x: x.lower())\n",
    "print(email_datasets.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59986df935687a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.418783Z",
     "start_time": "2024-06-05T20:01:58.318866Z"
    }
   },
   "source": [
    "# the next step is preprocessing and Tokenizing the data\n",
    "# this step Convert text into a sequence of tokens (numerical format) that the model can understand \n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "\n",
    "# Updates internal vocabulary with the words in the sequence memory\n",
    "tokenizer.fit_on_texts(email_datasets.message) \n",
    "\n",
    "# here we are converting to a sequence of numbers\n",
    "dataset_sequence = tokenizer.texts_to_sequences(email_datasets.message)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6c344dcae4d1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.562177Z",
     "start_time": "2024-06-05T20:01:58.419936Z"
    }
   },
   "source": [
    "# determining how to pad the letters so input will be equal\n",
    "# since I have chosen to find the most common highest value, with that value all sequence not up to that length will be padded\n",
    "sequence_lengths = [len(seq) for seq in dataset_sequence]\n",
    "\n",
    "sns.histplot(sequence_lengths, label='Message')\n",
    "\n",
    "# since the majority of the sequence length words falls within 10 we will pad all the sequences less than 10 "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2532b914a91b265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.573571Z",
     "start_time": "2024-06-05T20:01:58.563720Z"
    }
   },
   "source": [
    "padded_sequences = pad_sequences(dataset_sequence, maxlen=20)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7fe854b8428735",
   "metadata": {},
   "source": [
    "Training\n",
    "\n",
    "we now have the data in the right format, we can now split the data into training and testing set and since we will be using RNN we will be creating a function that will tune the model so we can take the best selection of hyperparameters, although this will be expensive in terms of time, but it will give us the best combination of hyperparameters that leads to the best model for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b992262da1b04bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:01:58.579052Z",
     "start_time": "2024-06-05T20:01:58.575496Z"
    }
   },
   "source": [
    "# split data into training and testing set using a ratio of 80:20\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, email_datasets.category, test_size=0.2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "baafff58766f52de",
   "metadata": {},
   "source": [
    "## Base Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c149a0a64a3ca93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:03:58.199574Z",
     "start_time": "2024-06-05T20:03:49.500310Z"
    }
   },
   "source": [
    "# choosing combination of hyperparameters\n",
    "# explanation of parameters \n",
    "\n",
    "# num of words\n",
    "# output_dim \n",
    "# epochs\n",
    "# batch_size\n",
    "# validation_split\n",
    "# activation_function\n",
    "# optimizer\n",
    "\n",
    "# embedding\\_dim & rnn\\_units & rnn\\_type & optimizer & activation & accuracy & loss & precision & recall \\\\\n",
    "# 100 & 64 & SimpleRNN & rmsprop & relu &  0.987444 & 0.061306 & 0.992701 & 0.912752 \\\\\n",
    "# 50 & 64 & LSTM & rmsprop & relu & 0.982960 & 0.080875 & 0.949367 & 0.931677 \\ \\\n",
    "# 50 & 32 & LSTM & rmsprop & relu &  0.989238 & 0.052878 & 0.987179 & 0.939024 \\\\\n",
    "\n",
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, output_dim=50))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(GRU(64, return_sequences = False))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model  \n",
    "\n",
    "\n",
    "def gru_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, output_dim=128))\n",
    "    model.add(GRU(128))\n",
    "    # model.add(GRU(64, return_sequences = False))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def simple_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, output_dim=50))\n",
    "    model.add(SimpleRNN(32))\n",
    "    # model.add(GRU(64, return_sequences = False))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model = gru_model()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', 'precision', 'recall'])\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, callbacks=[EarlyStopping(patience=3)])\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf10832be831156d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:04:11.898098Z",
     "start_time": "2024-06-05T20:04:11.774029Z"
    }
   },
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(x_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9faa769b737f001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:04:03.719241Z",
     "start_time": "2024-06-05T20:04:03.571047Z"
    }
   },
   "source": [
    "plot_model_history(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e549ee4d16cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:02:10.255440Z",
     "start_time": "2024-06-05T20:02:10.179677Z"
    }
   },
   "source": [
    "new_emails = [\n",
    "    \"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/123456 to claim now.\",\n",
    "    \"Hey, are we still on for the meeting tomorrow?\"\n",
    "]\n",
    "\n",
    "# Preprocess the new data\n",
    "new_sequences = tokenizer.texts_to_sequences(new_emails)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=20)\n",
    "\n",
    "# Make predictions\n",
    "predictions_prob = model.predict(new_padded)  # Probabilities\n",
    "\n",
    "predictions = [1 if prob > 0.5 else 0 for prob in predictions_prob]  # Binary classes\n",
    "\n",
    "# Output the predictions\n",
    "for email, prediction in zip(new_emails, predictions):\n",
    "    print(f\"Email: {email}\")\n",
    "    print(f\"Prediction: {'Spam' if prediction == 1 else 'Not Spam'}\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2120d63fd6e3421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:02:10.258610Z",
     "start_time": "2024-06-05T20:02:10.256469Z"
    }
   },
   "source": [
    "# plt confusion matrix\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "27c48be8a5d1553c",
   "metadata": {},
   "source": [
    "## Establishing benchmarks & comparing models\n",
    "\n",
    "- since we have a random section of test and training data we need an average of 5 runs to determine the benchmark of that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7497fea4095bd956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:56:07.754850Z",
     "start_time": "2024-06-05T21:55:29.702392Z"
    }
   },
   "source": [
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'embedding_dim': [50, 100, 200],\n",
    "    'rnn_units': [32, 64, 128],\n",
    "    'rnn_type': ['GRU'],\n",
    "    'dropout': [0.2, 0.4],\n",
    "    'optimizer': ['rmsprop', 'sgd'],\n",
    "    'batch_size': [32, 64],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "}\n",
    "\n",
    "# lstm_combinations = execute_grid_search(\n",
    "#     param_grid, x_train, y_train, x_test, y_test, num_words\n",
    "# )\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff521da5597ec9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:02:10.266349Z",
     "start_time": "2024-06-05T20:02:10.264394Z"
    }
   },
   "source": [
    "\n",
    "# print(lstm_combinations['table'].T)\n",
    "\n",
    "# print(lstm_combinations['best_accuracy'], lstm_combinations['best_model_accuracy'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f26663e6c0847d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:02:10.268756Z",
     "start_time": "2024-06-05T20:02:10.266964Z"
    }
   },
   "source": [
    "# results = lstm_combinations['table']\n",
    "\n",
    "# results['accuracy'] = results['accuracy'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "# print(results[results['accuracy'] > 0.99])\n",
    "\n",
    "# filtered_df = results[results['accuracy'] > 0.987]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4bd0b-db43-4dcc-beb7-cd18bf47960b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96906fab-c74d-4d5d-a6ba-231f3492679b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
